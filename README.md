# Learning_LLM
# My-first repository
Understanding and building GPT-like model.

Completed reading the book "Building a Large Language Model From Scratch" by Sebastian Raschka
as an LLM REsearcher intern at attentions.ai in Pune.

Recommended for beginners to understand basic concepts of LLM like Transformer architecture, decoder, enocoder,
pretraining, Top_k sampling, Temperature, Fine-tuning, Self-attention mechanism, Neural networks, Text-generation etc.

This repository contains the files that I used to understand and implement the code given in the book.
Most of the code will be similar to that of the book.
